{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnOWn5WP9IqP"
      },
      "source": [
        "# Homework: Galaxy Image Classification\n",
        "\n",
        "**Course:** Deep Learning for Computer Vision\n",
        "\n",
        "**Objective:** Train a deep learning model to classify galaxy images from the Galaxy10 DECals dataset into one of 10 categories.\n",
        "\n",
        "**Dataset:** Galaxy10 DECals\n",
        "* **Source:** [Hugging Face Datasets](https://huggingface.co/datasets/matthieulel/galaxy10_decals)\n",
        "* **Description:** Contains 17,736 color galaxy images (256x256 pixels) divided into 10 classes. Images originate from DESI Legacy Imaging Surveys, with labels from Galaxy Zoo.\n",
        "* **Classes:**\n",
        "    * 0: Disturbed Galaxies\n",
        "    * 1: Merging Galaxies\n",
        "    * 2: Round Smooth Galaxies\n",
        "    * 3: In-between Round Smooth Galaxies\n",
        "    * 4: Cigar Shaped Smooth Galaxies\n",
        "    * 5: Barred Spiral Galaxies\n",
        "    * 6: Unbarred Tight Spiral Galaxies\n",
        "    * 7: Unbarred Loose Spiral Galaxies\n",
        "    * 8: Edge-on Galaxies without Bulge\n",
        "    * 9: Edge-on Galaxies with Bulge\n",
        "\n",
        "**Tasks:**\n",
        "1.  Load and explore the dataset.\n",
        "2.  Preprocess the images.\n",
        "3.  Define and train a model.\n",
        "4.  Evaluate the model's performance using standard classification metrics on the test set.\n",
        "\n",
        "Homework is succesfully completed if you get >0.9 Accuracy on the Test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gip4I1f9ZE1"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhMtQ3zx5KjO"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# !pip install datasets scikit-learn matplotlib numpy -q >> None\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC6RCiNE-Wtm"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Visualize one example from each class\n",
        "def show_class_examples(dataset, class_names_map, samples_per_row=5, num_rows=2):\n",
        "    \"\"\"Displays one sample image for each class.\"\"\"\n",
        "    if not dataset:\n",
        "        print(\"Dataset not loaded. Cannot visualize.\")\n",
        "        return\n",
        "\n",
        "    num_classes_to_show = len(class_names_map)\n",
        "    if num_classes_to_show > samples_per_row * num_rows:\n",
        "        print(f\"Warning: Not enough space to show all {num_classes_to_show} classes.\")\n",
        "        num_classes_to_show = samples_per_row * num_rows\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, samples_per_row, figsize=(15, 6))  # Adjusted figsize\n",
        "    axes = axes.ravel()  # Flatten the axes array\n",
        "\n",
        "    split_name = \"train\" if \"train\" in dataset else list(dataset.keys())[0]\n",
        "    data_split = dataset[split_name]\n",
        "\n",
        "    images_shown = 0\n",
        "    processed_labels = set()\n",
        "\n",
        "    for i in range(len(data_split)):\n",
        "        if images_shown >= num_classes_to_show:\n",
        "            break  # Stop once we have shown one for each target class\n",
        "\n",
        "        example = data_split[i]\n",
        "        label = example[\"label\"]\n",
        "\n",
        "        if label not in processed_labels and label < num_classes_to_show:\n",
        "            img = example[\"image\"]\n",
        "            ax_idx = label  # Use label directly as index into the flattened axes\n",
        "            axes[ax_idx].imshow(img)\n",
        "            axes[ax_idx].set_title(f\"Class {label}: {class_names_map[label]}\", fontsize=9)\n",
        "            axes[ax_idx].axis(\"off\")\n",
        "            processed_labels.add(label)\n",
        "            images_shown += 1\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(images_shown, len(axes)):\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbdQ7g8R_91J"
      },
      "outputs": [],
      "source": [
        "def evaluate_predictions(predicted_labels, true_labels, class_names_list, silent=False):\n",
        "    \"\"\"\n",
        "    Calculates and prints classification metrics from predicted labels and true labels.\n",
        "\n",
        "    Args:\n",
        "        predicted_labels (list or np.array): The predicted class indices for the test set.\n",
        "        true_labels (list or np.array): The ground truth class indices for the test set.\n",
        "        class_names_list (list): A list of strings containing the names of the classes.\n",
        "    \"\"\"\n",
        "    if len(predicted_labels) != len(true_labels):\n",
        "        print(\n",
        "            f\"Error: Number of predictions ({len(predicted_labels)}) does not match number of true labels ({len(true_labels)}).\"\n",
        "        )\n",
        "        return None  # Indicate failure\n",
        "\n",
        "    print(f\"Evaluating {len(predicted_labels)} predictions against true labels...\")\n",
        "\n",
        "    # Ensure inputs are numpy arrays for scikit-learn\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Calculate metrics using scikit-learn\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    # Calculate precision, recall, f1 per class and average (weighted)\n",
        "    # Use zero_division=0 to handle cases where a class might not be predicted or present in labels\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, predicted_labels, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    # Get per-class metrics as well\n",
        "    per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
        "        true_labels, predicted_labels, average=None, zero_division=0, labels=range(len(class_names_list))\n",
        "    )\n",
        "\n",
        "    # Generate Confusion Matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=range(len(class_names_list)))\n",
        "\n",
        "    print(f\"\\n--- Evaluation Metrics ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Weighted Precision: {precision:.4f}\")\n",
        "    print(f\"Weighted Recall: {recall:.4f}\")\n",
        "    print(f\"Weighted F1-Score: {f1:.4f}\")\n",
        "\n",
        "    if not silent:\n",
        "        # Print Metrics\n",
        "        print(\"-\" * 25)\n",
        "        print(\"Per-Class Metrics:\")\n",
        "        print(f\"{'Class':<30} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10} | {'Support':<10}\")\n",
        "        print(\"-\" * 80)\n",
        "        for i, name in enumerate(class_names_list):\n",
        "            # Handle cases where support might be 0 for a class in true labels if dataset is small/filtered\n",
        "            support = per_class_support[i] if i < len(per_class_support) else 0\n",
        "            prec = per_class_precision[i] if i < len(per_class_precision) else 0\n",
        "            rec = per_class_recall[i] if i < len(per_class_recall) else 0\n",
        "            f1s = per_class_f1[i] if i < len(per_class_f1) else 0\n",
        "            print(f\"{f'{i}: {name}':<30} | {prec:<10.4f} | {rec:<10.4f} | {f1s:<10.4f} | {support:<10}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Plot Confusion Matrix\n",
        "        print(\"\\nPlotting Confusion Matrix...\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names_list)\n",
        "        disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=\"vertical\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "        plt.show()\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_weighted\": precision,\n",
        "        \"recall_weighted\": recall,\n",
        "        \"f1_weighted\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"per_class_metrics\": {\n",
        "            \"precision\": per_class_precision,\n",
        "            \"recall\": per_class_recall,\n",
        "            \"f1\": per_class_f1,\n",
        "            \"support\": per_class_support,\n",
        "        },\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyLXgwh-c_T"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y6Ve9zr-e2O",
        "outputId": "8ccb91b3-832c-4366-b8e6-84b1a79763bd"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"matthieulel/galaxy10_decals\"\n",
        "galaxy_dataset = datasets.load_dataset(dataset_name)\n",
        "\n",
        "# Define class names based on the dataset card\n",
        "class_names = [\n",
        "    \"Disturbed\",\n",
        "    \"Merging\",\n",
        "    \"Round Smooth\",\n",
        "    \"In-between Round Smooth\",\n",
        "    \"Cigar Shaped Smooth\",\n",
        "    \"Barred Spiral\",\n",
        "    \"Unbarred Tight Spiral\",\n",
        "    \"Unbarred Loose Spiral\",\n",
        "    \"Edge-on without Bulge\",\n",
        "    \"Edge-on with Bulge\",\n",
        "]\n",
        "\n",
        "# Create a dictionary for easy lookup\n",
        "label2name = {i: name for i, name in enumerate(class_names)}\n",
        "name2label = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(f\"\\nNumber of classes: {num_classes}\")\n",
        "print(\"Class names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "K5aJy1uR-oit",
        "outputId": "6bd04803-1f02-45c1-8521-1d71032a454d"
      },
      "outputs": [],
      "source": [
        "show_class_examples(galaxy_dataset, label2name, samples_per_row=5, num_rows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vLoIk4C-Xwg"
      },
      "source": [
        "# Your training code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSbFx86LaPjp",
        "outputId": "a2231113-37e0-4b77-ff8e-a6eadf03c655"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "galaxy_dataset_train = galaxy_dataset[\"train\"]\n",
        "galaxy_dataset_test = galaxy_dataset[\"test\"]\n",
        "\n",
        "train_img_transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.TrivialAugmentWide(), torchvision.transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "\n",
        "def train_transform(data):\n",
        "    res = {}\n",
        "    res[\"pixel_values\"] = [train_img_transform(img) for img in data[\"image\"]]\n",
        "    res[\"label\"] = [torch.tensor(label) for label in data[\"label\"]]\n",
        "    return res\n",
        "\n",
        "\n",
        "test_img_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def test_transform(data):\n",
        "    res = {}\n",
        "    res[\"pixel_values\"] = [test_img_transform(img) for img in data[\"image\"]]\n",
        "    res[\"label\"] = [torch.tensor(label) for label in data[\"label\"]]\n",
        "    return res\n",
        "\n",
        "\n",
        "galaxy_dataset_train = galaxy_dataset_train.with_transform(train_transform)\n",
        "galaxy_dataset_test = galaxy_dataset_test.with_transform(test_transform)\n",
        "\n",
        "print(galaxy_dataset_train[0][\"pixel_values\"].shape)\n",
        "print(galaxy_dataset_train[0][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import pywt\n",
        "from einops import rearrange, repeat\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "def sfb1d(lo, hi, g0, g1, mode=\"zero\", dim=-1):\n",
        "    \"\"\"1D synthesis filter bank of an image tensor\"\"\"\n",
        "    C = lo.shape[1]\n",
        "    d = dim % 4\n",
        "    # If g0, g1 are not tensors, make them. If they are, then assume that they\n",
        "    # are in the right order\n",
        "    if not isinstance(g0, torch.Tensor):\n",
        "        g0 = torch.tensor(np.copy(np.array(g0).ravel()), dtype=torch.float, device=lo.device)\n",
        "    if not isinstance(g1, torch.Tensor):\n",
        "        g1 = torch.tensor(np.copy(np.array(g1).ravel()), dtype=torch.float, device=lo.device)\n",
        "    L = g0.numel()\n",
        "    shape = [1, 1, 1, 1]\n",
        "    shape[d] = L\n",
        "    N = 2 * lo.shape[d]\n",
        "    # If g aren't in the right shape, make them so\n",
        "    if g0.shape != tuple(shape):\n",
        "        g0 = g0.reshape(*shape)\n",
        "    if g1.shape != tuple(shape):\n",
        "        g1 = g1.reshape(*shape)\n",
        "\n",
        "    s = (2, 1) if d == 2 else (1, 2)\n",
        "    g0 = torch.cat([g0] * C, dim=0)\n",
        "    g1 = torch.cat([g1] * C, dim=0)\n",
        "    if mode == \"per\" or mode == \"periodization\":\n",
        "        y = F.conv_transpose2d(lo, g0, stride=s, groups=C) + F.conv_transpose2d(hi, g1, stride=s, groups=C)\n",
        "        if d == 2:\n",
        "            y[:, :, : L - 2] = y[:, :, : L - 2] + y[:, :, N : N + L - 2]\n",
        "            y = y[:, :, :N]\n",
        "        else:\n",
        "            y[:, :, :, : L - 2] = y[:, :, :, : L - 2] + y[:, :, :, N : N + L - 2]\n",
        "            y = y[:, :, :, :N]\n",
        "        y = roll(y, 1 - L // 2, dim=dim)\n",
        "    else:\n",
        "        if mode == \"zero\" or mode == \"symmetric\" or mode == \"reflect\" or mode == \"periodic\":\n",
        "            pad = (L - 2, 0) if d == 2 else (0, L - 2)\n",
        "            y = F.conv_transpose2d(lo, g0, stride=s, padding=pad, groups=C) + F.conv_transpose2d(\n",
        "                hi, g1, stride=s, padding=pad, groups=C\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Unkown pad type: {}\".format(mode))\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def reflect(x, minx, maxx):\n",
        "    \"\"\"Reflect the values in matrix *x* about the scalar values *minx* and\n",
        "    *maxx*.  Hence a vector *x* containing a long linearly increasing series is\n",
        "    converted into a waveform which ramps linearly up and down between *minx*\n",
        "    and *maxx*.  If *x* contains integers and *minx* and *maxx* are (integers +\n",
        "    0.5), the ramps will have repeated max and min samples.\n",
        "    .. codeauthor:: Rich Wareham <rjw57@cantab.net>, Aug 2013\n",
        "    .. codeauthor:: Nick Kingsbury, Cambridge University, January 1999.\n",
        "    \"\"\"\n",
        "    x = np.asanyarray(x)\n",
        "    rng = maxx - minx\n",
        "    rng_by_2 = 2 * rng\n",
        "    mod = np.fmod(x - minx, rng_by_2)\n",
        "    normed_mod = np.where(mod < 0, mod + rng_by_2, mod)\n",
        "    out = np.where(normed_mod >= rng, rng_by_2 - normed_mod, normed_mod) + minx\n",
        "    return np.array(out, dtype=x.dtype)\n",
        "\n",
        "\n",
        "def mode_to_int(mode):\n",
        "    if mode == \"zero\":\n",
        "        return 0\n",
        "    elif mode == \"symmetric\":\n",
        "        return 1\n",
        "    elif mode == \"per\" or mode == \"periodization\":\n",
        "        return 2\n",
        "    elif mode == \"constant\":\n",
        "        return 3\n",
        "    elif mode == \"reflect\":\n",
        "        return 4\n",
        "    elif mode == \"replicate\":\n",
        "        return 5\n",
        "    elif mode == \"periodic\":\n",
        "        return 6\n",
        "    else:\n",
        "        raise ValueError(\"Unkown pad type: {}\".format(mode))\n",
        "\n",
        "\n",
        "def int_to_mode(mode):\n",
        "    if mode == 0:\n",
        "        return \"zero\"\n",
        "    elif mode == 1:\n",
        "        return \"symmetric\"\n",
        "    elif mode == 2:\n",
        "        return \"periodization\"\n",
        "    elif mode == 3:\n",
        "        return \"constant\"\n",
        "    elif mode == 4:\n",
        "        return \"reflect\"\n",
        "    elif mode == 5:\n",
        "        return \"replicate\"\n",
        "    elif mode == 6:\n",
        "        return \"periodic\"\n",
        "    else:\n",
        "        raise ValueError(\"Unkown pad type: {}\".format(mode))\n",
        "\n",
        "\n",
        "def afb1d(x, h0, h1, mode=\"zero\", dim=-1):\n",
        "    \"\"\"1D analysis filter bank (along one dimension only) of an image\n",
        "    Inputs:\n",
        "        x (tensor): 4D input with the last two dimensions the spatial input\n",
        "        h0 (tensor): 4D input for the lowpass filter. Should have shape (1, 1,\n",
        "            h, 1) or (1, 1, 1, w)\n",
        "        h1 (tensor): 4D input for the highpass filter. Should have shape (1, 1,\n",
        "            h, 1) or (1, 1, 1, w)\n",
        "        mode (str): padding method\n",
        "        dim (int) - dimension of filtering. d=2 is for a vertical filter (called\n",
        "            column filtering but filters across the rows). d=3 is for a\n",
        "            horizontal filter, (called row filtering but filters across the\n",
        "            columns).\n",
        "    Returns:\n",
        "        lohi: lowpass and highpass subbands concatenated along the channel\n",
        "            dimension\n",
        "    \"\"\"\n",
        "    C = x.shape[1]\n",
        "    # Convert the dim to positive\n",
        "    d = dim % 4\n",
        "    s = (2, 1) if d == 2 else (1, 2)\n",
        "    N = x.shape[d]\n",
        "    # If h0, h1 are not tensors, make them. If they are, then assume that they\n",
        "    # are in the right order\n",
        "    if not isinstance(h0, torch.Tensor):\n",
        "        h0 = torch.tensor(np.copy(np.array(h0).ravel()[::-1]), dtype=torch.float, device=x.device)\n",
        "    if not isinstance(h1, torch.Tensor):\n",
        "        h1 = torch.tensor(np.copy(np.array(h1).ravel()[::-1]), dtype=torch.float, device=x.device)\n",
        "    L = h0.numel()\n",
        "    L2 = L // 2\n",
        "    shape = [1, 1, 1, 1]\n",
        "    shape[d] = L\n",
        "    # If h aren't in the right shape, make them so\n",
        "    if h0.shape != tuple(shape):\n",
        "        h0 = h0.reshape(*shape)\n",
        "    if h1.shape != tuple(shape):\n",
        "        h1 = h1.reshape(*shape)\n",
        "    h = torch.cat([h0, h1] * C, dim=0)\n",
        "\n",
        "    if mode == \"per\" or mode == \"periodization\":\n",
        "        if x.shape[dim] % 2 == 1:\n",
        "            if d == 2:\n",
        "                x = torch.cat((x, x[:, :, -1:]), dim=2)\n",
        "            else:\n",
        "                x = torch.cat((x, x[:, :, :, -1:]), dim=3)\n",
        "            N += 1\n",
        "        x = roll(x, -L2, dim=d)\n",
        "        pad = (L - 1, 0) if d == 2 else (0, L - 1)\n",
        "        lohi = F.conv2d(x, h.to(x.device), padding=pad, stride=s, groups=C)\n",
        "        N2 = N // 2\n",
        "        if d == 2:\n",
        "            lohi[:, :, :L2] = lohi[:, :, :L2] + lohi[:, :, N2 : N2 + L2]\n",
        "            lohi = lohi[:, :, :N2]\n",
        "        else:\n",
        "            lohi[:, :, :, :L2] = lohi[:, :, :, :L2] + lohi[:, :, :, N2 : N2 + L2]\n",
        "            lohi = lohi[:, :, :, :N2]\n",
        "    else:\n",
        "        # Calculate the pad size\n",
        "        outsize = pywt.dwt_coeff_len(N, L, mode=mode)\n",
        "        p = 2 * (outsize - 1) - N + L\n",
        "        if mode == \"zero\":\n",
        "            # Sadly, pytorch only allows for same padding before and after, if\n",
        "            # we need to do more padding after for odd length signals, have to\n",
        "            # prepad\n",
        "            if p % 2 == 1:\n",
        "                pad = (0, 0, 0, 1) if d == 2 else (0, 1, 0, 0)\n",
        "                x = F.pad(x, pad)\n",
        "            pad = (p // 2, 0) if d == 2 else (0, p // 2)\n",
        "            # Calculate the high and lowpass\n",
        "            lohi = F.conv2d(x, h.to(x.device), padding=pad, stride=s, groups=C)\n",
        "        elif mode == \"symmetric\" or mode == \"reflect\" or mode == \"periodic\":\n",
        "            pad = (0, 0, p // 2, (p + 1) // 2) if d == 2 else (p // 2, (p + 1) // 2, 0, 0)\n",
        "            x = mypad(x, pad=pad, mode=mode)\n",
        "            lohi = F.conv2d(x, h.to(x.device), stride=s, groups=C)\n",
        "        else:\n",
        "            raise ValueError(\"Unkown pad type: {}\".format(mode))\n",
        "\n",
        "    return lohi\n",
        "\n",
        "\n",
        "class AFB2D(Function):\n",
        "    \"\"\"Does a single level 2d wavelet decomposition of an input. Does separate\n",
        "    row and column filtering by two calls to\n",
        "    :py:func:`pytorch_wavelets.dwt.lowlevel.afb1d`\n",
        "    Needs to have the tensors in the right form. Because this function defines\n",
        "    its own backward pass, saves on memory by not having to save the input\n",
        "    tensors.\n",
        "    Inputs:\n",
        "        x (torch.Tensor): Input to decompose\n",
        "        h0_row: row lowpass\n",
        "        h1_row: row highpass\n",
        "        h0_col: col lowpass\n",
        "        h1_col: col highpass\n",
        "        mode (int): use mode_to_int to get the int code here\n",
        "    We encode the mode as an integer rather than a string as gradcheck causes an\n",
        "    error when a string is provided.\n",
        "    Returns:\n",
        "        y: Tensor of shape (N, C*4, H, W)\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, h0_row, h1_row, h0_col, h1_col, mode):\n",
        "        ctx.save_for_backward(h0_row, h1_row, h0_col, h1_col)\n",
        "        ctx.shape = x.shape[-2:]\n",
        "        mode = int_to_mode(mode)\n",
        "        ctx.mode = mode\n",
        "        lohi = afb1d(x, h0_row, h1_row, mode=mode, dim=3)\n",
        "        y = afb1d(lohi, h0_col, h1_col, mode=mode, dim=2)\n",
        "        s = y.shape\n",
        "        y = y.reshape(s[0], -1, 4, s[-2], s[-1])\n",
        "        low = y[:, :, 0].contiguous()\n",
        "        highs = y[:, :, 1:].contiguous()\n",
        "        return low, highs\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, low, highs):\n",
        "        dx = None\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            mode = ctx.mode\n",
        "            h0_row, h1_row, h0_col, h1_col = ctx.saved_tensors\n",
        "            lh, hl, hh = torch.unbind(highs, dim=2)\n",
        "            lo = sfb1d(low, lh, h0_col, h1_col, mode=mode, dim=2)\n",
        "            hi = sfb1d(hl, hh, h0_col, h1_col, mode=mode, dim=2)\n",
        "            dx = sfb1d(lo, hi, h0_row, h1_row, mode=mode, dim=3)\n",
        "            if dx.shape[-2] > ctx.shape[-2] and dx.shape[-1] > ctx.shape[-1]:\n",
        "                dx = dx[:, :, : ctx.shape[-2], : ctx.shape[-1]]\n",
        "            elif dx.shape[-2] > ctx.shape[-2]:\n",
        "                dx = dx[:, :, : ctx.shape[-2]]\n",
        "            elif dx.shape[-1] > ctx.shape[-1]:\n",
        "                dx = dx[:, :, :, : ctx.shape[-1]]\n",
        "        return dx, None, None, None, None, None\n",
        "\n",
        "\n",
        "def prep_filt_afb2d(h0_col, h1_col, h0_row=None, h1_row=None, device='cpu'):\n",
        "    \"\"\"\n",
        "    Prepares the filters to be of the right form for the afb2d function.  In\n",
        "    particular, makes the tensors the right shape. It takes mirror images of\n",
        "    them as as afb2d uses conv2d which acts like normal correlation.\n",
        "    Inputs:\n",
        "        h0_col (array-like): low pass column filter bank\n",
        "        h1_col (array-like): high pass column filter bank\n",
        "        h0_row (array-like): low pass row filter bank. If none, will assume the\n",
        "            same as column filter\n",
        "        h1_row (array-like): high pass row filter bank. If none, will assume the\n",
        "            same as column filter\n",
        "        device: which device to put the tensors on to\n",
        "    Returns:\n",
        "        (h0_col, h1_col, h0_row, h1_row)\n",
        "    \"\"\"\n",
        "    h0_col, h1_col = prep_filt_afb1d(h0_col, h1_col, device)\n",
        "    if h0_row is None:\n",
        "        h0_row, h1_col = h0_col, h1_col\n",
        "    else:\n",
        "        h0_row, h1_row = prep_filt_afb1d(h0_row, h1_row, device)\n",
        "\n",
        "    h0_col = h0_col.reshape((1, 1, -1, 1))\n",
        "    h1_col = h1_col.reshape((1, 1, -1, 1))\n",
        "    h0_row = h0_row.reshape((1, 1, 1, -1))\n",
        "    h1_row = h1_row.reshape((1, 1, 1, -1))\n",
        "    return h0_col, h1_col, h0_row, h1_row\n",
        "\n",
        "\n",
        "def prep_filt_afb1d(h0, h1, device='cpu'):\n",
        "    \"\"\"\n",
        "    Prepares the filters to be of the right form for the afb2d function.  In\n",
        "    particular, makes the tensors the right shape. It takes mirror images of\n",
        "    them as as afb2d uses conv2d which acts like normal correlation.\n",
        "    Inputs:\n",
        "        h0 (array-like): low pass column filter bank\n",
        "        h1 (array-like): high pass column filter bank\n",
        "        device: which device to put the tensors on to\n",
        "    Returns:\n",
        "        (h0, h1)\n",
        "    \"\"\"\n",
        "    h0 = np.array(h0[::-1]).ravel()\n",
        "    h1 = np.array(h1[::-1]).ravel()\n",
        "    t = torch.get_default_dtype()\n",
        "    h0 = torch.tensor(h0, device=device, dtype=t).reshape((1, 1, -1))\n",
        "    h1 = torch.tensor(h1, device=device, dtype=t).reshape((1, 1, -1))\n",
        "    return h0, h1\n",
        "\n",
        "\n",
        "class DWTForward(nn.Module):\n",
        "    \"\"\"Performs a 2d DWT Forward decomposition of an image\n",
        "    Args:\n",
        "        J (int): Number of levels of decomposition\n",
        "        wave (str or pywt.Wavelet or tuple(ndarray)): Which wavelet to use.\n",
        "            Can be:\n",
        "            1) a string to pass to pywt.Wavelet constructor\n",
        "            2) a pywt.Wavelet class\n",
        "            3) a tuple of numpy arrays, either (h0, h1) or (h0_col, h1_col, h0_row, h1_row)\n",
        "        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. The\n",
        "            padding scheme\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, J=1, wave=\"db1\", mode=\"zero\"):\n",
        "        super().__init__()\n",
        "        if isinstance(wave, str):\n",
        "            wave = pywt.Wavelet(wave)\n",
        "        if isinstance(wave, pywt.Wavelet):\n",
        "            h0_col, h1_col = wave.dec_lo, wave.dec_hi\n",
        "            h0_row, h1_row = h0_col, h1_col\n",
        "        else:\n",
        "            if len(wave) == 2:\n",
        "                h0_col, h1_col = wave[0], wave[1]\n",
        "                h0_row, h1_row = h0_col, h1_col\n",
        "            elif len(wave) == 4:\n",
        "                h0_col, h1_col = wave[0], wave[1]\n",
        "                h0_row, h1_row = wave[2], wave[3]\n",
        "\n",
        "        # Prepare the filters\n",
        "        filts = prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n",
        "        self.register_buffer(\"h0_col\", filts[0])\n",
        "        self.register_buffer(\"h1_col\", filts[1])\n",
        "        self.register_buffer(\"h0_row\", filts[2])\n",
        "        self.register_buffer(\"h1_row\", filts[3])\n",
        "        self.J = J\n",
        "        self.mode = mode\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the DWT.\n",
        "        Args:\n",
        "            x (tensor): Input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n",
        "        Returns:\n",
        "            (yl, yh)\n",
        "                tuple of lowpass (yl) and bandpass (yh) coefficients.\n",
        "                yh is a list of length J with the first entry\n",
        "                being the finest scale coefficients. yl has shape\n",
        "                :math:`(N, C_{in}, H_{in}', W_{in}')` and yh has shape\n",
        "                :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. The new\n",
        "                dimension in yh iterates over the LH, HL and HH coefficients.\n",
        "        Note:\n",
        "            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n",
        "            downsampled shapes of the DWT pyramid.\n",
        "        \"\"\"\n",
        "        yh = []\n",
        "        ll = x\n",
        "        mode = mode_to_int(self.mode)\n",
        "\n",
        "        # Do a multilevel transform\n",
        "        for j in range(self.J):\n",
        "            # Do 1 level of the transform\n",
        "            ll, high = AFB2D.apply(ll, self.h0_col, self.h1_col, self.h0_row, self.h1_row, mode)\n",
        "            yh.append(high)\n",
        "\n",
        "        return ll, yh\n",
        "    \n",
        "def get_dwt_filters(level, mode='zero', wave='db1'):   \n",
        "    xf = []\n",
        "    for j in range(1,level+1,1):\n",
        "        xf.append(DWTForward(J=j, mode=mode, wave=wave))\n",
        "\n",
        "    if level == 1: \n",
        "        xf = xf[0]\n",
        "\n",
        "    return xf\n",
        "\n",
        "\n",
        "class Level1Waveblock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        mult=2,\n",
        "        ff_channel=16,\n",
        "        final_dim=16,\n",
        "        dropout=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Conv2d(final_dim, final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, final_dim, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(final_dim),\n",
        "        )\n",
        "\n",
        "        self.reduction = nn.Conv2d(final_dim, int(final_dim / 4), 1)\n",
        "\n",
        "        self.xf1 = get_dwt_filters(level=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        Y1, Yh = self.xf1(x)\n",
        "\n",
        "        x = torch.reshape(Yh[0], (b, int(c * 3 / 4), int(h / 2), int(w / 2)))\n",
        "\n",
        "        x = torch.cat((Y1, x), dim=1)\n",
        "\n",
        "        x = self.feedforward(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Level2Waveblock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        mult=2,\n",
        "        ff_channel=16,\n",
        "        final_dim=16,\n",
        "        dropout=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feedforward1 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, final_dim, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(final_dim),\n",
        "        )\n",
        "\n",
        "        self.feedforward2 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim, final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.reduction = nn.Conv2d(final_dim, int(final_dim / 4), 1)\n",
        "\n",
        "        self.xf1, self.xf2 = get_dwt_filters(level=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        Y1, Yh = self.xf1(x)\n",
        "        Y2, Yh = self.xf2(x)\n",
        "\n",
        "        x1 = torch.reshape(Yh[0], (b, int(c * 3 / 4), int(h / 2), int(w / 2)))\n",
        "        x2 = torch.reshape(Yh[1], (b, int(c * 3 / 4), int(h / 4), int(w / 4)))\n",
        "\n",
        "        x1 = torch.cat((Y1, x1), dim=1)\n",
        "        x2 = torch.cat((Y2, x2), dim=1)\n",
        "\n",
        "        x2 = self.feedforward2(x2)\n",
        "\n",
        "        x1 = torch.cat((x1, x2), dim=1)\n",
        "        x = self.feedforward1(x1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Level3Waveblock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        mult=2,\n",
        "        ff_channel=16,\n",
        "        final_dim=16,\n",
        "        dropout=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feedforward1 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, final_dim, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(final_dim),\n",
        "        )\n",
        "\n",
        "        self.feedforward2 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.feedforward3 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim, final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.reduction = nn.Conv2d(final_dim, int(final_dim / 4), 1)\n",
        "\n",
        "        self.xf1, self.xf2, self.xf3 = get_dwt_filters(level=3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        Y1, Yh = self.xf1(x)\n",
        "        Y2, Yh = self.xf2(x)\n",
        "        Y3, Yh = self.xf3(x)\n",
        "\n",
        "        x1 = torch.reshape(Yh[0], (b, int(c * 3 / 4), int(h / 2), int(w / 2)))\n",
        "        x2 = torch.reshape(Yh[1], (b, int(c * 3 / 4), int(h / 4), int(w / 4)))\n",
        "        x3 = torch.reshape(Yh[2], (b, int(c * 3 / 4), int(h / 8), int(w / 8)))\n",
        "\n",
        "        x1 = torch.cat((Y1, x1), dim=1)\n",
        "        x2 = torch.cat((Y2, x2), dim=1)\n",
        "        x3 = torch.cat((Y3, x3), dim=1)\n",
        "\n",
        "        x3 = self.feedforward3(x3)\n",
        "\n",
        "        x2 = torch.cat((x2, x3), dim=1)\n",
        "\n",
        "        x2 = self.feedforward2(x2)\n",
        "\n",
        "        x1 = torch.cat((x1, x2), dim=1)\n",
        "        x = self.feedforward1(x1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Level4Waveblock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        mult=2,\n",
        "        ff_channel=16,\n",
        "        final_dim=16,\n",
        "        dropout=0.5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.feedforward1 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, final_dim, 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(final_dim),\n",
        "        )\n",
        "\n",
        "        self.feedforward2 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.feedforward3 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim + int(final_dim / 2), final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.feedforward4 = nn.Sequential(\n",
        "            nn.Conv2d(final_dim, final_dim * mult, 1),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv2d(final_dim * mult, ff_channel, 1),\n",
        "            nn.ConvTranspose2d(ff_channel, int(final_dim / 2), 4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(int(final_dim / 2)),\n",
        "        )\n",
        "\n",
        "        self.reduction = nn.Conv2d(final_dim, int(final_dim / 4), 1)\n",
        "\n",
        "        self.xf1, self.xf2, self.xf3, self.xf4 = get_dwt_filters(level=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        x = self.reduction(x)\n",
        "\n",
        "        Y1, Yh = self.xf1(x)\n",
        "        Y2, Yh = self.xf2(x)\n",
        "        Y3, Yh = self.xf3(x)\n",
        "        Y4, Yh = self.xf4(x)\n",
        "\n",
        "        x1 = torch.reshape(Yh[0], (b, int(c * 3 / 4), int(h / 2), int(w / 2)))\n",
        "        x2 = torch.reshape(Yh[1], (b, int(c * 3 / 4), int(h / 4), int(w / 4)))\n",
        "        x3 = torch.reshape(Yh[2], (b, int(c * 3 / 4), int(h / 8), int(w / 8)))\n",
        "        x4 = torch.reshape(Yh[3], (b, int(c * 3 / 4), int(h / 16), int(w / 16)))\n",
        "\n",
        "        x1 = torch.cat((Y1, x1), dim=1)\n",
        "        x2 = torch.cat((Y2, x2), dim=1)\n",
        "        x3 = torch.cat((Y3, x3), dim=1)\n",
        "        x4 = torch.cat((Y4, x4), dim=1)\n",
        "\n",
        "        x4 = self.feedforward4(x4)\n",
        "\n",
        "        x3 = torch.cat((x3, x4), dim=1)\n",
        "\n",
        "        x3 = self.feedforward3(x3)\n",
        "\n",
        "        x2 = torch.cat((x2, x3), dim=1)\n",
        "\n",
        "        x2 = self.feedforward2(x2)\n",
        "\n",
        "        x1 = torch.cat((x1, x2), dim=1)\n",
        "        x = self.feedforward1(x1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "\n",
        "class WaveMix(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        num_classes=1000,\n",
        "        depth=16,\n",
        "        mult=2,\n",
        "        ff_channel=192,\n",
        "        final_dim=192,\n",
        "        dropout=0.5,\n",
        "        patch_size=4,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(Level4Waveblock(mult=mult, ff_channel=ff_channel, final_dim=final_dim, dropout=dropout))\n",
        "\n",
        "        self.pool = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), Rearrange(\"... () () -> ...\"), nn.Linear(final_dim, num_classes)\n",
        "        )\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, int(final_dim / 4), 3, 1, 1),\n",
        "            nn.Conv2d(int(final_dim / 4), int(final_dim / 2), 3, 1, 1),\n",
        "            nn.Conv2d(int(final_dim / 2), final_dim, patch_size, patch_size),\n",
        "            nn.GELU(),\n",
        "            nn.BatchNorm2d(final_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, pixel_values, labels=None):\n",
        "        x = self.conv(pixel_values)\n",
        "\n",
        "        for attn in self.layers:\n",
        "            x = attn(x) + x\n",
        "\n",
        "        logits = self.pool(x)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "\n",
        "        return {\"loss\": loss, \"logits\": logits}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "NEIax7vd9-kA",
        "outputId": "fa99a707-4801-47ce-bd45-48677419e98f"
      },
      "outputs": [],
      "source": [
        "print(\"Creating model...\")\n",
        "\n",
        "model = WaveMix(\n",
        "    num_classes=num_classes,\n",
        "    depth=16,\n",
        "    mult=2,\n",
        "    ff_channel=192,\n",
        "    final_dim=192,\n",
        "    dropout=0.5,\n",
        "    patch_size=4,\n",
        ").to(device, dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.trainer import Trainer\n",
        "from transformers import TrainingArguments\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    stats = evaluate_predictions(predictions, labels, class_names, silent=True)\n",
        "    stats.pop(\"confusion_matrix\")\n",
        "    stats.pop(\"per_class_metrics\")\n",
        "    return stats\n",
        "\n",
        "\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 0.01\n",
        "ADAM_EPSILON = 1e-6  # Potentially more stable than 1e-8\n",
        "WARMUP_RATIO = 0.05  # Use 5% of total steps for linear warmup\n",
        "LR_SCHEDULER_TYPE = \"cosine\"  # Common and effective scheduler\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=50,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    save_strategy=\"epoch\",\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=1,\n",
        "    optim=\"sgd\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    # weight_decay=WEIGHT_DECAY,\n",
        "    # adam_beta1=0.9,\n",
        "    # adam_beta2=0.999,\n",
        "    # adam_epsilon=ADAM_EPSILON,\n",
        "    # lr_scheduler_type=LR_SCHEDULER_TYPE,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    bf16=True,\n",
        "    # fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=galaxy_dataset_train,\n",
        "    eval_dataset=galaxy_dataset_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcU22RKA_4eF"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_dataset_test_processed = (\n",
        "    galaxy_dataset[\"test\"]\n",
        "    .map(test_transform, batched=True, batch_size=128, remove_columns=[\"image\"])\n",
        "    .with_format(\"torch\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_dataset_test_batched = galaxy_dataset_test_processed.batch(batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = []\n",
        "for batch in galaxy_dataset_test_batched:\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    preds += model.forward(torch.tensor(batch[\"pixel_values\"]).to(device))[\"logits\"].argmax(dim=-1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcR0CLbx_5Ws"
      },
      "outputs": [],
      "source": [
        "true_test_labels = galaxy_dataset[\"test\"][\"label\"]\n",
        "test_metrics = evaluate_predictions(preds, true_test_labels, class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7Gip4I1f9ZE1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
