{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnOWn5WP9IqP"
      },
      "source": [
        "# Homework: Galaxy Image Classification\n",
        "\n",
        "**Course:** Deep Learning for Computer Vision\n",
        "\n",
        "**Objective:** Train a deep learning model to classify galaxy images from the Galaxy10 DECals dataset into one of 10 categories.\n",
        "\n",
        "**Dataset:** Galaxy10 DECals\n",
        "* **Source:** [Hugging Face Datasets](https://huggingface.co/datasets/matthieulel/galaxy10_decals)\n",
        "* **Description:** Contains 17,736 color galaxy images (256x256 pixels) divided into 10 classes. Images originate from DESI Legacy Imaging Surveys, with labels from Galaxy Zoo.\n",
        "* **Classes:**\n",
        "    * 0: Disturbed Galaxies\n",
        "    * 1: Merging Galaxies\n",
        "    * 2: Round Smooth Galaxies\n",
        "    * 3: In-between Round Smooth Galaxies\n",
        "    * 4: Cigar Shaped Smooth Galaxies\n",
        "    * 5: Barred Spiral Galaxies\n",
        "    * 6: Unbarred Tight Spiral Galaxies\n",
        "    * 7: Unbarred Loose Spiral Galaxies\n",
        "    * 8: Edge-on Galaxies without Bulge\n",
        "    * 9: Edge-on Galaxies with Bulge\n",
        "\n",
        "**Tasks:**\n",
        "1.  Load and explore the dataset.\n",
        "2.  Preprocess the images.\n",
        "3.  Define and train a model.\n",
        "4.  Evaluate the model's performance using standard classification metrics on the test set.\n",
        "\n",
        "Homework is succesfully completed if you get >0.9 Accuracy on the Test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Gip4I1f9ZE1"
      },
      "source": [
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhMtQ3zx5KjO"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# !pip install datasets scikit-learn matplotlib numpy -q >> None\n",
        "\n",
        "import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PC6RCiNE-Wtm"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Visualize one example from each class\n",
        "def show_class_examples(dataset, class_names_map, samples_per_row=5, num_rows=2):\n",
        "    \"\"\"Displays one sample image for each class.\"\"\"\n",
        "    if not dataset:\n",
        "        print(\"Dataset not loaded. Cannot visualize.\")\n",
        "        return\n",
        "\n",
        "    num_classes_to_show = len(class_names_map)\n",
        "    if num_classes_to_show > samples_per_row * num_rows:\n",
        "        print(f\"Warning: Not enough space to show all {num_classes_to_show} classes.\")\n",
        "        num_classes_to_show = samples_per_row * num_rows\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, samples_per_row, figsize=(15, 6))  # Adjusted figsize\n",
        "    axes = axes.ravel()  # Flatten the axes array\n",
        "\n",
        "    split_name = \"train\" if \"train\" in dataset else list(dataset.keys())[0]\n",
        "    data_split = dataset[split_name]\n",
        "\n",
        "    images_shown = 0\n",
        "    processed_labels = set()\n",
        "\n",
        "    for i in range(len(data_split)):\n",
        "        if images_shown >= num_classes_to_show:\n",
        "            break  # Stop once we have shown one for each target class\n",
        "\n",
        "        example = data_split[i]\n",
        "        label = example[\"label\"]\n",
        "\n",
        "        if label not in processed_labels and label < num_classes_to_show:\n",
        "            img = example[\"image\"]\n",
        "            ax_idx = label  # Use label directly as index into the flattened axes\n",
        "            axes[ax_idx].imshow(img)\n",
        "            axes[ax_idx].set_title(f\"Class {label}: {class_names_map[label]}\", fontsize=9)\n",
        "            axes[ax_idx].axis(\"off\")\n",
        "            processed_labels.add(label)\n",
        "            images_shown += 1\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(images_shown, len(axes)):\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbdQ7g8R_91J"
      },
      "outputs": [],
      "source": [
        "def evaluate_predictions(predicted_labels, true_labels, class_names_list, silent=False):\n",
        "    \"\"\"\n",
        "    Calculates and prints classification metrics from predicted labels and true labels.\n",
        "\n",
        "    Args:\n",
        "        predicted_labels (list or np.array): The predicted class indices for the test set.\n",
        "        true_labels (list or np.array): The ground truth class indices for the test set.\n",
        "        class_names_list (list): A list of strings containing the names of the classes.\n",
        "    \"\"\"\n",
        "    if len(predicted_labels) != len(true_labels):\n",
        "        print(\n",
        "            f\"Error: Number of predictions ({len(predicted_labels)}) does not match number of true labels ({len(true_labels)}).\"\n",
        "        )\n",
        "        return None  # Indicate failure\n",
        "\n",
        "    print(f\"Evaluating {len(predicted_labels)} predictions against true labels...\")\n",
        "\n",
        "    # Ensure inputs are numpy arrays for scikit-learn\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Calculate metrics using scikit-learn\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    # Calculate precision, recall, f1 per class and average (weighted)\n",
        "    # Use zero_division=0 to handle cases where a class might not be predicted or present in labels\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, predicted_labels, average=\"weighted\", zero_division=0\n",
        "    )\n",
        "    # Get per-class metrics as well\n",
        "    per_class_precision, per_class_recall, per_class_f1, per_class_support = precision_recall_fscore_support(\n",
        "        true_labels, predicted_labels, average=None, zero_division=0, labels=range(len(class_names_list))\n",
        "    )\n",
        "\n",
        "    # Generate Confusion Matrix\n",
        "    cm = confusion_matrix(true_labels, predicted_labels, labels=range(len(class_names_list)))\n",
        "\n",
        "    print(f\"\\n--- Evaluation Metrics ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Weighted Precision: {precision:.4f}\")\n",
        "    print(f\"Weighted Recall: {recall:.4f}\")\n",
        "    print(f\"Weighted F1-Score: {f1:.4f}\")\n",
        "\n",
        "    if not silent:\n",
        "        # Print Metrics\n",
        "        print(\"-\" * 25)\n",
        "        print(\"Per-Class Metrics:\")\n",
        "        print(f\"{'Class':<30} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10} | {'Support':<10}\")\n",
        "        print(\"-\" * 80)\n",
        "        for i, name in enumerate(class_names_list):\n",
        "            # Handle cases where support might be 0 for a class in true labels if dataset is small/filtered\n",
        "            support = per_class_support[i] if i < len(per_class_support) else 0\n",
        "            prec = per_class_precision[i] if i < len(per_class_precision) else 0\n",
        "            rec = per_class_recall[i] if i < len(per_class_recall) else 0\n",
        "            f1s = per_class_f1[i] if i < len(per_class_f1) else 0\n",
        "            print(f\"{f'{i}: {name}':<30} | {prec:<10.4f} | {rec:<10.4f} | {f1s:<10.4f} | {support:<10}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Plot Confusion Matrix\n",
        "        print(\"\\nPlotting Confusion Matrix...\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names_list)\n",
        "        disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=\"vertical\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "        plt.show()\n",
        "\n",
        "    metrics = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision_weighted\": precision,\n",
        "        \"recall_weighted\": recall,\n",
        "        \"f1_weighted\": f1,\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"per_class_metrics\": {\n",
        "            \"precision\": per_class_precision,\n",
        "            \"recall\": per_class_recall,\n",
        "            \"f1\": per_class_f1,\n",
        "            \"support\": per_class_support,\n",
        "        },\n",
        "    }\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpyLXgwh-c_T"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y6Ve9zr-e2O",
        "outputId": "8ccb91b3-832c-4366-b8e6-84b1a79763bd"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"matthieulel/galaxy10_decals\"\n",
        "galaxy_dataset = datasets.load_dataset(dataset_name)\n",
        "\n",
        "# Define class names based on the dataset card\n",
        "class_names = [\n",
        "    \"Disturbed\",\n",
        "    \"Merging\",\n",
        "    \"Round Smooth\",\n",
        "    \"In-between Round Smooth\",\n",
        "    \"Cigar Shaped Smooth\",\n",
        "    \"Barred Spiral\",\n",
        "    \"Unbarred Tight Spiral\",\n",
        "    \"Unbarred Loose Spiral\",\n",
        "    \"Edge-on without Bulge\",\n",
        "    \"Edge-on with Bulge\",\n",
        "]\n",
        "\n",
        "# Create a dictionary for easy lookup\n",
        "label2name = {i: name for i, name in enumerate(class_names)}\n",
        "name2label = {name: i for i, name in enumerate(class_names)}\n",
        "\n",
        "num_classes = len(class_names)\n",
        "print(f\"\\nNumber of classes: {num_classes}\")\n",
        "print(\"Class names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "K5aJy1uR-oit",
        "outputId": "6bd04803-1f02-45c1-8521-1d71032a454d"
      },
      "outputs": [],
      "source": [
        "show_class_examples(galaxy_dataset, label2name, samples_per_row=5, num_rows=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vLoIk4C-Xwg"
      },
      "source": [
        "# Your training code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSbFx86LaPjp",
        "outputId": "a2231113-37e0-4b77-ff8e-a6eadf03c655"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "print(\"Loading data...\")\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "dtype = torch.bfloat16\n",
        "\n",
        "torch.set_default_dtype(dtype)\n",
        "\n",
        "galaxy_dataset_train = galaxy_dataset[\"train\"]\n",
        "galaxy_dataset_test = galaxy_dataset[\"test\"]\n",
        "\n",
        "train_img_transform = torchvision.transforms.Compose(\n",
        "    [torchvision.transforms.TrivialAugmentWide(), torchvision.transforms.ToTensor()]\n",
        ")\n",
        "\n",
        "\n",
        "def train_transform(data):\n",
        "    res = {}\n",
        "    res[\"pixel_values\"] = [train_img_transform(img) for img in data[\"image\"]]\n",
        "    res[\"label\"] = [torch.tensor(label) for label in data[\"label\"]]\n",
        "    return res\n",
        "\n",
        "\n",
        "test_img_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "\n",
        "def test_transform(data):\n",
        "    res = {}\n",
        "    res[\"pixel_values\"] = [test_img_transform(img) for img in data[\"image\"]]\n",
        "    res[\"label\"] = [torch.tensor(label) for label in data[\"label\"]]\n",
        "    return res\n",
        "\n",
        "\n",
        "galaxy_dataset_train = galaxy_dataset_train.with_transform(train_transform)\n",
        "galaxy_dataset_test = galaxy_dataset_test.with_transform(test_transform)\n",
        "\n",
        "print(galaxy_dataset_train[0][\"pixel_values\"].shape)\n",
        "print(galaxy_dataset_train[0][\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "NEIax7vd9-kA",
        "outputId": "fa99a707-4801-47ce-bd45-48677419e98f"
      },
      "outputs": [],
      "source": [
        "from zoobot.pytorch.training.finetune import FinetuneableZoobotClassifier\n",
        "\n",
        "print(\"Creating model...\")\n",
        "\n",
        "model = FinetuneableZoobotClassifier(\n",
        "    # arguments for any FinetuneableZoobot class\n",
        "    # there are many options for customizing finetuning. See the FinetuneableZoobotAbstract docstring.\n",
        "    name=\"hf_hub:mwalmsley/zoobot-encoder-convnext_nano\",\n",
        "    n_blocks=5,  # Finetune this many blocks. Set 0 for only the head. Set e.g. 1, 2 to finetune deeper (5 max for convnext).\n",
        "    learning_rate=1e-5,  # use a low learning rate\n",
        "    lr_decay=0.5,  # reduce the learning rate from lr to lr^0.5 for each block deeper in the network\n",
        "    # arguments specific to FinetuneableZoobotClassifier\n",
        "    num_classes=num_classes,\n",
        ").to(device, dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers.trainer import Trainer\n",
        "from transformers import TrainingArguments\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    stats = evaluate_predictions(predictions, labels, class_names, silent=True)\n",
        "    stats.pop(\"confusion_matrix\")\n",
        "    stats.pop(\"per_class_metrics\")\n",
        "    return stats\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./zoobot_res\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        "    save_strategy=\"epoch\",\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=1,\n",
        "    bf16=True,\n",
        "    # fp16=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=galaxy_dataset_train,\n",
        "    eval_dataset=galaxy_dataset_test,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "trainer.train(resume_from_checkpoint=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcU22RKA_4eF"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_dataset_test_processed = (\n",
        "    galaxy_dataset[\"test\"]\n",
        "    .map(test_transform, batched=True, batch_size=128, remove_columns=[\"image\"])\n",
        "    .with_format(\"torch\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_dataset_test_batched = galaxy_dataset_test_processed.batch(batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = []\n",
        "for batch in galaxy_dataset_test_batched:\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    preds += model.forward(torch.tensor(batch[\"pixel_values\"]).to(device))[\"logits\"].argmax(dim=-1).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcR0CLbx_5Ws"
      },
      "outputs": [],
      "source": [
        "true_test_labels = galaxy_dataset[\"test\"][\"label\"]\n",
        "test_metrics = evaluate_predictions(preds, true_test_labels, class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "7Gip4I1f9ZE1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
